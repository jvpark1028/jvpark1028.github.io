<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic+Coding&display=swap" rel="stylesheet">
</head>
<link rel="stylesheet" href="ai.css"/>
<body>
    
    <h1>인공지능(AI)의 원리 탐구</h1><br><br>

    <div>
        <h2><mark>AI의 기본적인 원리</mark></h2>
        <p>
            생성형 ai는 <b>심층 신경 학습망</b>이라는 기술을 이용하여 학습<br><br>
            <b>심층 신경 학습망</b>이란 사람의 두뇌기반으로 계층적 네트워크로 많은 레이어에 데이터를 훈련하여 수행되는 일종의 머신 러닝 기술이다.<br><br>
            쉽게 말하자면 이전의 반복과 경험을 바탕으로 해결책을 예측하고 결론을 도출하여 작동하도록 설계한다는 것이다.<br><br>
            인공지능의 학습은 한마디 모델이 데이터의 패턴의 특징을 인지, 오차를 최소화하는 방향으로 스스로를 조정하는 과정을 뜻함<br><br>
        </p><br>
    </div>
    <div>
        <h2><mark>챗 gpt의 원리와 심화학습</mark></h2>
        <p>
            가장 사람들이 많이 사용하는 생성형 AI인 ChatGPT에 대해 우리는 심화 탐구를 하였다.<br><br>
            1시간 가까이 알아본 결과, 챗GPT는 <b>RLHF 강화 학습법</b>을 사용한다는 것을 알게 되었다.<br><br>
            <b>RLHF 강화 학습법</b>이란 쉽게 말하자면 사람의 피드백을 이용하여 강화 학습을 시키는 것이다.<br><br>
            <b>RLHF 강화 학습법</b>는 총 3단계로 이루어 져있다. 각 과정들에 대해 알아보자
        </p><br>
    </div>
    <div>
        <h2><mark>RLHF 강화 학습법의 세부 단계</mark></h2>
        <h3><mark>1. 언어 모델 사전 훈련 (Pretraining Language Model)</mark></h3>
        <p>
            OpenAI는 인터넷에서 떠도는 데이터 전체를 신뢰 X <br><br>
            그렇기 때문에 신뢰할 수 있는 질문과 답안만을 가지고 지도 학습시킴.<br><br>
            여기까지는 일반적인 언어 모델과 동일.
        </p><br>
        <h3><mark>2. 피드백으로 모델 훈련 (Reward Model training)</mark></h3>
        <p>
            1단계에서 언어 모델에 질문을 하고 여러 답변을 받기.<br><br>
            그렇게 생성된 여러 답변 중 질문자의 의도와 부합하는지 평가해 순위를 매김<br><br>
            이를 별도로 데이터베이스화하고 이 데이터를 이용해 학습을 반복하면서 답변 우선순위를 예측하도록 함.
        </p>
        <h3><mark>3. 1/2단계로 미세조정 (Fine-tuning with RL)</mark></h3>
        <p>
            3단계는 <b>PPO</b>(Proximal Policy Optimization) 알고리즘을 사용하여 언어 모델의 파라미터(특정한 성질을 나타내는 변수) 일부 또는 전체를 조정하는 방법을 사용.<br>

            여기서 <b>PPO 알고리즘</b>이란 강화 학습 알고리즘의 한 종류.<br>
            Episode 단위로 반영하는 것이아닌 Step 단위로 학습데이터를 만들어 내어 학습하는 방식, 즉 학습데이터를 재사용하는 모델로 학습 효과를 높이는 방식을 말함.<br><br>

            학습에 사용한 데이터가 아닌 새로운 질문으로 생성된 답변을 보고 문제점을 미세하게 조정하는 단계.<br><br>
            선별된 데이터세트로 진행한 1~2단계의 과정의 결과가 갖고 있는 한계를 극복하고 정확도를 높이기 위함임.<br><br>
            언어 모델의 경우에는 질문에 정확하게 답변할 가능성과 실제 정확하게 답변한 사례를 분석하는 데 사용.
        </p><br>
        
    </div>
    <p>by 박준후 혼자서 새벽 1시에</p>
</body>
</html>